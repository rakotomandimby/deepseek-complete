# Propose inline suggestions from DeepSeek API

The final purpose of this project is to be an inline suggestion plugin that uses the DeepSeek API to suggest.
But we are not going to implement everything in one step, we are to make it step by step.

- Generate random sentences
- Make an inline suggestion from a random sentence when triggered.
- Have the possibility transform the inline suggestion into regular text (accepting the suggestion).
- Get the content of the current buffer know how to split it into 2 parts: 
    - the first part is the text from the begining of the buffer to the cursor position
    - the second part is the text from the cursor position to the end of the buffer
- Query the DeepSeek API to get suggestions from the content of the buffer.
- Use the DeepSeek API response to suggest completions (dont use the random sentences anymore)

## Step 1: Generate a random sentence

in `./lua/rktmb-deepseek-complete.lua`, there is a function called `generate_sentence()`.
That function generates a multiline random sentence.
This is done.

## Step 2: Make an inline  suggestion from a random sentence when triggered.

When I am in a buffer and in INSERT mode and issue the key sequence `<M-PageDown>`,
The plugin to place de cursor at the end of the line and then insert an inline suggestion 
taken from a random sentence (which is multi line) picked from the list of sentences.
The suggestion appears in grey (#808080).
The suggestion pushes down the lines below it and does not overlap with the text below.
If I continue to type after the suggestion is displayed, the suggestion disappears.
As far as I type, I can trigger the suggestion again and if I continue to type, the suggestion disappears, again and again.

That is the desired behavior.

## Step 3: Have the possibility transform the inline suggestion into regular text (accepting the suggestion).

Now the current code allows to transform the inline suggestion into regular text with the `<M-PageUp>` key sequence.

## Step 4: Get the text before and after the cursor then log it into the logs

When in INSERT mode and issue the `<M-PageDown>` key sequence:
- the cursor goes the end of the current line
- the content from the beginning of the line to the cursor position is stored in a variable
- the content from the cursor position to the end of the buffer is stored in a variable
- the logs confirms the 2 variables has the correct content

That is the desired behavior. Let's continue to implement the remaining steps without breaking the current features.

## Step 5: Query the DeepSeek API to get suggestions from the content of the buffer.

With the current code, the plugin makes a POST request to the DeepSeek API and fetches the API response.
API response a multi-line string, just like the random sentences are.

## Step 6: Dont use the random sentences anymore, but use the API response

We reach the final step, where we will use the API response instead of the random sentences.

Tell me what do I have to change in the code so that when I press `<M-PageDown>` in INSERT mode, the plugin will use the API response instead of the random sentences.




# This is o1-preview answer (3k in, 5k out)

To make the plugin use the DeepSeek API response instead of the random sentences when you press `<M-PageDown>`, you'll need to modify the code in your `plugin/init.lua` file. Currently, your function `_G.suggest_random_sentence` generates a random sentence using `generate_sentence()` and displays it as an inline suggestion.

Here's what you need to do:

1. **Modify the `process_deepseek_response` function to display the API response as an inline suggestion.**

2. **Update the `_G.suggest_random_sentence` function to remove the random sentence generation and rely on the API response instead.**

Below are the detailed steps and code changes:

---

### **Step 1: Modify `process_deepseek_response` to Display the API Response**

In your `plugin/init.lua`, the `process_deepseek_response` function currently processes the API response and logs it but doesn't display it as an inline suggestion. You'll need to adjust this function to extract the suggestion from the API response and display it.

**Here's how you can modify the function:**

```lua
local function process_deepseek_response(response)
  if response.status == 200 then
    rktmb_deepseek_complete.log("DeepSeek status: 200")
    vim.schedule(function()
      rktmb_deepseek_complete.log("DeepSeek in the schedule")
      local body = vim.fn.json_decode(response.body)
      if body.choices and #body.choices > 0 then
        -- Extract the first choice from the API response
        local choice = body.choices[1]
        local suggestion = choice.message.content

        -- Remove Markdown code block delimiters if present
        suggestion = rktmb_deepseek_complete.remove_markdown_start_code_block_delimiter(suggestion)
        suggestion = rktmb_deepseek_complete.remove_markdown_end_code_block_delimiter(suggestion)
        rktmb_deepseek_complete.log("Suggestion from DeepSeek API:")
        rktmb_deepseek_complete.log(suggestion)

        -- Split the suggestion into lines
        local lines = vim.split(suggestion, "\n", true)

        -- Store the suggestion globally
        _G.current_suggestion = lines

        -- Construct virt_lines with proper formatting
        local virt_lines = {}
        for _, line in ipairs(lines) do
          table.insert(virt_lines, { { line, "Comment" } }) -- Use "Comment" highlight group for grey text
        end

        -- Get the current cursor position
        local cursor_position_table = vim.api.nvim_win_get_cursor(0)
        local current_row = cursor_position_table[1] - 1 -- Adjust for 0-based index

        -- Set the extmark with virt_lines
        local extmark_id = vim.api.nvim_buf_set_extmark(0, ns_id, current_row, 0, {
          virt_lines = virt_lines,
          virt_lines_above = false, -- Place the virtual lines below the current line
          hl_mode = 'combine'       -- Combine with existing text highlighting
        })

        -- Store the extmark ID globally
        _G.current_extmark_id = extmark_id

        -- Clear the suggestion on text change or insert leave
        local augroup_id = vim.api.nvim_create_augroup("RktmbDeepseekCompleteSuggestions", { clear = true })
        vim.api.nvim_create_autocmd({ "TextChangedI", "InsertLeave" }, {
          group = augroup_id,
          buffer = 0,
          callback = function()
            vim.api.nvim_buf_del_extmark(0, ns_id, extmark_id)
            _G.current_extmark_id = nil
            _G.current_suggestion = nil
            vim.api.nvim_del_augroup_by_id(augroup_id)
          end
        })
      else
        rktmb_deepseek_complete.log("DeepSeek API returned no choices.")
      end
    end)
  else
    rktmb_deepseek_complete.log("DeepSeek API request failed with status: " .. tostring(response.status))
    rktmb_deepseek_complete.log("Response body:\n" .. response.body)
  end
end
```

**Explanation:**

- **Extract the Suggestion:** We extract the content of the first choice from the API response.
- **Process the Suggestion:** Remove any Markdown code block delimiters from the suggestion.
- **Display the Suggestion:**
  - Split the suggestion into lines.
  - Store the suggestion in `_G.current_suggestion` for later use (e.g., when accepting the suggestion).
  - Construct virtual lines (`virt_lines`) to display the suggestion inline using Neovim's virtual text feature.
  - Place the virtual lines below the current line where the cursor is.
- **Handle Suggestion Lifecycle:**
  - Create an autocommand group to clear the suggestion when the user types (`TextChangedI`) or leaves insert mode (`InsertLeave`).
  - Remove the extmark (virtual text) and clear the global variables when the suggestion is cleared.

---

### **Step 2: Update `_G.suggest_random_sentence` to Use the API Response**

Now, you'll need to modify the `_G.suggest_random_sentence` function to remove the random sentence generation and rely solely on the API response.

**Here's how you can modify the function:**

```lua
_G.suggest_random_sentence = function()
  local cursor_position_table = vim.api.nvim_win_get_cursor(0)
  local current_row = cursor_position_table[1]
  local current_col = cursor_position_table[2]

  -- Ensure the cursor is at the end of the current line
  local current_line = vim.api.nvim_get_current_line()
  vim.api.nvim_win_set_cursor(0, { current_row, #current_line })

  cursor_position_table = vim.api.nvim_win_get_cursor(0)
  current_row = cursor_position_table[1]
  current_col = cursor_position_table[2]

  -- Get buffer content before and after cursor
  local current_buffer = vim.api.nvim_get_current_buf()
  local lines = vim.api.nvim_buf_get_lines(current_buffer, 0, -1, false)
  local text_before_cursor = table.concat(lines, "\n", 1, current_row - 1) .. "\n" .. string.sub(lines[current_row], 1, current_col)
  local text_after_cursor = string.sub(lines[current_row], current_col + 1) .. "\n" .. table.concat(lines, "\n", current_row + 1)
  local line_the_cursor_is_on = string.sub(lines[current_row], current_col + 1)

  -- Log the text before and after the cursor (optional)
  rktmb_deepseek_complete.log("Text before cursor:\n" .. text_before_cursor)
  rktmb_deepseek_complete.log("Text after cursor:\n" .. text_after_cursor)

  -- Make the DeepSeek API request
  local deepseek_request_body = {
    model = "deepseek-chat",
    echo = false,
    frequency_penalty = 0,
    max_tokens = 1024,
    presence_penalty = 0,
    stop = nil,
    stream = false,
    stream_options = nil,
    temperature = 1,
    top_p = 1,
    messages = {
      { role = "system", content = "You are a software developer assistant that will complete code based on the context provided. Just answer with indented raw code, NO explanations, NO markdown formatting." },
      { role = "user", content = "I need you to complete code." },
      { role = "assistant", content = "What is before the cursor?" },
      { role = "user", content = text_before_cursor },
      { role = "assistant", content = "What is after the cursor?" },
      { role = "user", content = text_after_cursor },
      { role = "assistant", content = "What line do you want me to continue?" },
      { role = "user", content = "Continue this line: \n" .. line_the_cursor_is_on }
    }
  }

  -- Retrieve the API token
  local deepseek_api_token = os.getenv("DEEPSEEK_API_KEY")

  -- Asynchronously make the POST request
  curl.post('https://api.deepseek.com/chat/completions', {
    body = vim.fn.json_encode(deepseek_request_body),
    headers = {
      ["Content-Type"] = "application/json",
      ["Accept"] = "application/json",
      ["Authorization"] = "Bearer " .. deepseek_api_token
    },
    callback = function(response)
      process_deepseek_response(response)
    end
  })

  -- Remove or comment out the random sentence generation
  --[[
  -- Generate the random sentence
  local sentence = rktmb_deepseek_complete.generate_sentence()
  lines = vim.split(sentence, "\n", true)

  -- Store the suggestion globally
  _G.current_suggestion = lines

  -- Construct virt_lines with proper formatting
  local virt_lines = {}
  for _, line in ipairs(lines) do
    table.insert(virt_lines, { { line, "Comment" } }) -- Use "Comment" highlight group for grey text
  end

  -- Set the extmark with virt_lines
  local extmark_id = vim.api.nvim_buf_set_extmark(0, ns_id, current_row - 1, 0, {
    virt_lines = virt_lines,
    virt_lines_above = false, -- Place the virtual lines below the current line
    hl_mode = 'combine'       -- Combine with existing text highlighting
  })

  -- Store the extmark ID globally
  _G.current_extmark_id = extmark_id

  -- Clear the suggestion on text change or insert leave
  local augroup_id = vim.api.nvim_create_augroup("RktmbDeepseekCompleteSuggestions", { clear = true })
  vim.api.nvim_create_autocmd({ "TextChangedI", "InsertLeave" }, {
    group = augroup_id,
    buffer = 0,
    callback = function()
      vim.api.nvim_buf_del_extmark(0, ns_id, extmark_id)
      _G.current_extmark_id = nil
      _G.current_suggestion = nil
      vim.api.nvim_del_augroup_by_id(augroup_id)
    end
  })
  ]]
end
```

**Explanation:**

- **Remove Random Sentence Generation:** Commented out the code that generates and displays the random sentence using `generate_sentence()` since we no longer need it.
- **Make API Request:** The function now focuses on making the API request and relies on the callback (`process_deepseek_response`) to handle the response and display the suggestion.

---

### **Step 3: Test the Changes**

After making these changes, test the plugin:

- Enter **INSERT** mode in Neovim.
- Press `<M-PageDown>`.
- The plugin should:

  - Move the cursor to the end of the current line.
  - Collect the text before the cursor and after the cursor.
  - Send a request to the DeepSeek API with the appropriate context.
  - Upon receiving the response, extract the suggestion.
  - Display the suggestion inline, below your current line, in grey text.

- The suggestion should disappear if you continue typing.
- You can accept the suggestion by pressing `<M-PageUp>`.

---

### **Additional Notes and Tips**

- **Ensure Environment Variable is Set:**

  - Make sure the `DEEPSEEK_API_KEY` environment variable is set with your actual DeepSeek API key.
  - You can set it in your shell profile or use a plugin like [direnv](https://github.com/direnv/direnv) to manage environment variables per project.

- **Error Handling:**

  - The provided code includes basic error logging.
  - You might want to enhance error handling to cover cases like network errors or unexpected API responses.

- **Customize the API Request:**

  - Adjust the `messages` array in `deepseek_request_body` if you want to change the prompt or system instructions.
  - Ensure that the content sent to the API provides enough context for meaningful suggestions.

- **Adjust Display Settings:**

  - If the suggestion doesn't appear as expected, you might need to tweak the positioning or highlighting.
  - The `virt_lines_above` and `hl_mode` options in `vim.api.nvim_buf_set_extmark` control how and where the suggestion appears.

- **Debugging:**

  - Use `rktmb_deepseek_complete.log` to log messages to `/tmp/rktmb-deepseek-complete.log` for debugging purposes.
  - Check the log file if the suggestion doesn't appear or you encounter issues.

---

### **Example of Modified Functions**

**Modified `process_deepseek_response`:**

```lua
local function process_deepseek_response(response)
  if response.status == 200 then
    -- [Code as shown above]
  else
    -- [Error handling code]
  end
end
```

**Modified `_G.suggest_random_sentence`:**

```lua
_G.suggest_random_sentence = function()
  -- [Code as shown above]
end
```

---

### **Summary**

By making these changes, you're effectively replacing the random sentence generation with the real suggestions from the DeepSeek API. The plugin now:

- **Collects Context:**
  - Captures the text before and after the cursor to send as context to the API.

- **Requests Completion:**
  - Sends a request to the DeepSeek API for code completion.

- **Displays Suggestion:**
  - Displays the API's response as an inline suggestion, just like it did previously with the random sentences.

- **Handles User Interaction:**
  - The suggestion disappears when you continue typing.
  - You can accept the suggestion by pressing `<M-PageUp>`.

---

**Let me know if you need further assistance or if you encounter any issues with these changes!**

