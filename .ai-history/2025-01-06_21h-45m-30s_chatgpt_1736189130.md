# Propose inline suggestions from DeepSeek API

The final purpose of this project is to be an inline suggestion plugin that uses the DeepSeek API to suggest.
But we are not going to implement everything in one step, we are to make it step by step.

- Generate random sentences
- Make an inline suggestion from a random sentence when triggered.
- Have the possibility transform the inline suggestion into regular text (accepting the suggestion).
- Get the content of the current buffer know how to split it into 2 parts: 
    - the first part is the text from the begining of the buffer to the cursor position
    - the second part is the text from the cursor position to the end of the buffer
- Query the DeepSeek API to get suggestions from the content of the buffer.
- Use the DeepSeek API response to suggest completions (dont use the random sentences anymore)

## Step 1: Generate a random sentence

in `./lua/rktmb-deepseek-complete.lua`, there is a function called `generate_sentence()`.
That function generates a multiline random sentence.
This is done.

## Step 2: Make an inline  suggestion from a random sentence when triggered.

When I am in a buffer and in INSERT mode and issue the key sequence `<M-PageDown>`,
The plugin to place de cursor at the end of the line and then insert an inline suggestion 
taken from a random sentence (which is multi line) picked from the list of sentences.
The suggestion appears in grey (#808080).
The suggestion pushes down the lines below it and does not overlap with the text below.
If I continue to type after the suggestion is displayed, the suggestion disappears.
As far as I type, I can trigger the suggestion again and if I continue to type, the suggestion disappears, again and again.

That is the desired behavior.

## Step 3: Have the possibility transform the inline suggestion into regular text (accepting the suggestion).

Now the current code allows to transform the inline suggestion into regular text with the `<M-PageUp>` key sequence.

## Step 4: Get the text before and after the cursor then log it into the logs

When in INSERT mode and issue the `<M-PageDown>` key sequence:
- the cursor goes the end of the current line
- the content from the beginning of the line to the cursor position is stored in a variable
- the content from the cursor position to the end of the buffer is stored in a variable
- the logs confirms the 2 variables has the correct content

That is the desired behavior. Let's continue to implement the remaining steps without breaking the current features.

## Step 5: Query the DeepSeek API to get suggestions from the content of the buffer.

According to the DeepSeek API documentation, the API expects a POST request with the following body:

```
curl -L -X POST 'https://api.deepseek.com/chat/completions' \
-H 'Content-Type: application/json' \
-H 'Accept: application/json' \
-H 'Authorization: Bearer <TOKEN>' \
--data-raw '{
  "messages": [
    {"content": "You are a helpful assistant", "role": "system"},
    {"content": "Hi","role": "user"}
  ],
  "model": "deepseek-chat",
  "frequency_penalty": 0,
  "max_tokens": 2048,
  "presence_penalty": 0,
  "response_format": {
    "type": "text"
  },
  "stop": null,
  "stream": false,
  "stream_options": null,
  "temperature": 1,
  "top_p": 1,
  "tools": null,
  "tool_choice": "none",
  "logprobs": false,
  "top_logprobs": null
}'
```

I use "plenary.nvim" to make the HTTP requests.
For the moment, I log the DeepSeek API response into the logs.

The problem with the code in `./plugin/init.lua` is that `vim.fn.json_encode` which is used to encode the request body cannot be called inside a callback.

But I want the `choices[].text` to be displayed in the logs.

Propose me the modifications to `./plugin/init.lua` to achieve what I want.




# This is gpt-4o-mini answer (2k in, 1k out)

To achieve the desired functionality of querying the DeepSeek API and logging the response while ensuring that `vim.fn.json_encode` is called outside of the callback, we need to make some modifications to the `./plugin/init.lua` file. Below are the proposed changes:

### Updated `plugin/init.lua`

```lua
local rktmb_deepseek_complete = require("rktmb-deepseek-complete")
local curl = require('plenary.curl')

_G.ns_id = vim.api.nvim_create_namespace('rktmb-deepseek-complete')

_G.current_extmark_id = nil
_G.current_suggestion = nil

_G.suggest_random_sentence = function()
  local cursor_position_table = vim.api.nvim_win_get_cursor(0)
  local current_row = cursor_position_table[1]
  local current_col = cursor_position_table[2]

  -- Ensure the cursor is at the end of the current line
  local current_line = vim.api.nvim_get_current_line()
  vim.api.nvim_win_set_cursor(0, {current_row, #current_line})

  cursor_position_table = vim.api.nvim_win_get_cursor(0)
  current_row = cursor_position_table[1]
  current_col = cursor_position_table[2]

  -- Get buffer content before and after cursor
  local current_buffer = vim.api.nvim_get_current_buf()
  local lines = vim.api.nvim_buf_get_lines(current_buffer, 0, -1, false)
  local text_before_cursor = table.concat(lines, "\n", 1, current_row - 1) .. "\n" .. string.sub(lines[current_row], 1, current_col)
  local text_after_cursor = string.sub(lines[current_row], current_col + 1) .. "\n" .. table.concat(lines, "\n", current_row + 1)
  local line_the_cursor_is_on = string.sub(lines[current_row], current_col + 1)

  -- Log the text before and after cursor
  rktmb_deepseek_complete.log("Text before cursor:\n" .. text_before_cursor)
  rktmb_deepseek_complete.log("Text after cursor:\n" .. text_after_cursor)

  -- Make the DeepSeek API request
  local deepseek_request_body = {
    model = "deepseek-chat",
    echo = false,
    frequency_penalty = 0,
    max_tokens = 2048,
    presence_penalty = 0,
    stop = nil,
    stream = false,
    stream_options = nil,
    temperature = 1,
    top_p = 1,
    messages = {
      {role = "system", content = "You are a helpful assistant."},
      {role = "user", content = text_before_cursor},
      {role = "assistant", content = "What do you want me to continue?"},
      {role = "user", content = line_the_cursor_is_on}
    }
  }

  -- Replace '<TOKEN>' with your actual DeepSeek API token
  local deepseek_api_token = os.getenv("DEEPSEEK_API_KEY")

  -- Encode the request body outside of the callback
  local request_body = vim.fn.json_encode(deepseek_request_body)

  -- Asynchronously make the POST request
  curl.post('https://api.deepseek.com/chat/completions', {
    body = request_body,
    headers = {
      ["Content-Type"] = "application/json",
      ["Accept"] = "application/json",
      ["Authorization"] = "Bearer " .. deepseek_api_token
    },
    callback = function(response)
      if response.status == 200 then
        -- Log the API response
        rktmb_deepseek_complete.log("DeepSeek API response:\n" .. response.body)
        -- json decode the response body
        local body = vim.fn.json_decode(response.body)

        -- response.body is a Lua table of choices
        -- Loop on the choices and display them
        for _, choice in pairs(body.choices) do
          rktmb_deepseek_complete.log("Suggestion: " .. choice.text)
          rktmb_deepseek_complete.log("===========================")
        end
      else
        -- Log the error
        rktmb_deepseek_complete.log("DeepSeek API request failed with status: " .. tostring(response.status))
        rktmb_deepseek_complete.log("Response body:\n" .. response.body)
      end
    end
  })

  -- Generate the random sentence
  local sentence = rktmb_deepseek_complete.generate_sentence()
  lines = vim.split(sentence, "\n", true)

  -- Store the suggestion globally
  _G.current_suggestion = lines

  -- Construct virt_lines with proper formatting
  local virt_lines = {}
  for _, line in ipairs(lines) do
    table.insert(virt_lines, { { line, "Comment" } }) -- Use "Comment" highlight group for grey text
  end

  -- Set the extmark with virt_lines
  local extmark_id = vim.api.nvim_buf_set_extmark(0, ns_id, current_row - 1, 0, {
    virt_lines = virt_lines,
    virt_lines_above = false, -- Place the virtual lines below the current line
    hl_mode = 'combine'       -- Combine with existing text highlighting
  })

  -- Store the extmark ID globally
  _G.current_extmark_id = extmark_id

  -- Clear the suggestion on text change or insert leave
  local augroup_id = vim.api.nvim_create_augroup("RktmbDeepseekCompleteSuggestions", { clear = true })
  vim.api.nvim_create_autocmd({ "TextChangedI", "InsertLeave" }, {
    group = augroup_id,
    buffer = 0,
    callback = function()
      vim.api.nvim_buf_del_extmark(0, ns_id, extmark_id)
      _G.current_extmark_id = nil
      _G.current_suggestion = nil
      vim.api.nvim_del_augroup_by_id(augroup_id)
    end
  })
end

_G.accept_suggestion = function()
  if not _G.current_extmark_id or not _G.current_suggestion then
    -- No active suggestion to accept
    return
  end

  local bufnr = 0
  local cursor_pos = vim.api.nvim_win_get_cursor(0)
  local current_line = cursor_pos[1]

  vim.api.nvim_buf_set_lines(bufnr, current_line, current_line, false, _G.current_suggestion)
  vim.api.nvim_win_set_cursor(0, { current_line + #_G.current_suggestion, 0 })
  vim.api.nvim_buf_del_extmark(bufnr, ns_id, _G.current_extmark_id)

  _G.current_extmark_id = nil
  _G.current_suggestion = nil
end

vim.api.nvim_create_autocmd("InsertLeave", {
  pattern = "*",
  callback = function()
    vim.api.nvim_buf_clear_namespace(0, ns_id, 0, -1)
  end
})

vim.api.nvim_set_keymap("i", "<M-PageDown>", "<Cmd>lua suggest_random_sentence()<CR>", { noremap = true, silent = true })
vim.api.nvim_set_keymap("i", "<M-PageUp>", "<Cmd>lua accept_suggestion()<CR>", { noremap = true, silent = true })
```

### Key Changes Made:
1. **Logging Text Before and After Cursor**: Added logging for the text before and after the cursor when the `<M-PageDown>` key sequence is triggered.
2. **Request Body Encoding**: Moved the `vim.fn.json_encode` call outside of the callback to ensure it is executed properly.
3. **DeepSeek API Request**: Updated the request body to match the expected format for the DeepSeek API, using the text before the cursor and the line where the cursor is located.

With these changes, the plugin will now log the text before and after the cursor, and it will be able to query the DeepSeek API for suggestions based on the current buffer content.

