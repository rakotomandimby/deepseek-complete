-- From the list of buffers, build the following table:
-- {
--   { role= "assistant", content= "give me the content od <buffer_name>" },
--   { role= "user", content= "<buffer_content>" },
--   { role= "assistant", content= "give me the content od <buffer_name>" },
--   { role= "user", content= "<buffer_content>" },
--   { role= "assistant", content= "give me the content od <buffer_name>" },
--   { role= "user", content= "<buffer_content>" },
--   { role= "assistant", content= "give me the content od <buffer_name>" },
--   { role= "user", content= "<buffer_content>" },
--   ...
-- }



# This is gemini-exp-1206 answer (3k in, 0k out)

You're asking to build a table of messages suitable for a large language model, incorporating the content of all open buffers in Neovim.  Here's the modified `lua/rktmb-deepseek-complete.lua` file with the function `M.build_messages_table`:

```lua
-- lua/rktmb-deepseek-complete.lua
local M = {}

-- ... (Existing functions: log, remove_markdown_delimiters, get_open_buffers, get_buffer_content)

function M.build_messages_table()
  local buffers = M.get_open_buffers()
  local messages = {}

  for _, buf in ipairs(buffers) do
    local filename = vim.api.nvim_buf_get_name(buf)
    local content = M.get_buffer_content(buf)

    table.insert(messages, { role = "assistant", content = "Give me the content of " .. filename })
    table.insert(messages, { role = "user", content = content })
  end

  return messages
end

return M
```

No changes are needed in your `plugin/init.lua` unless you want to use this new function.  Here's how you might use it within your plugin, for example, to include the buffer contents in your DeepSeek request:

```lua
-- plugin/init.lua  (Modified section within _G.suggest)

-- ... (Existing code)

local messages = rktmb_deepseek_complete.build_messages_table()

-- Incorporate the messages into the DeepSeek request
local deepseek_request_body = {
  model = "deepseek-chat",
  -- ... other parameters
  messages = {
    { role = "system", content = "You are a software developer assistant. Consider the content of the following files when answering the subsequent prompt." },
    -- Add the messages from the buffers
    { role = "user", content = table.concat(messages) },
    { role = "user", content = "I need you to complete code." },
    { role = "assistant", content = "What is before the cursor?" },
    { role = "user", content = text_before_cursor },
    { role = "assistant", content = "What is after the cursor?" },
    { role = "user", content = text_after_cursor },
    { role = "assistant", content = "What line do you want me to continue?" },
    { role = "user", content = "Continue this line: \n" .. line_the_cursor_is_on }
  }
}

-- ... (Rest of your existing code)
```

This revised approach first builds the table of messages using the new function and then inserts it into the `messages` field of your DeepSeek request.  This provides context from all open buffers to the language model.  Remember to adjust the system message accordingly.  Also, be mindful of token limits when sending large amounts of data.  You might need to filter or truncate the buffer content if it exceeds the model's capacity.
